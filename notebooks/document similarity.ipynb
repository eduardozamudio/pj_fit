{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic similarity\n",
    "\n",
    "The aim of this notebook is to test a strategy to measure similarity between an **expert profile** and **project description**. \n",
    "\n",
    "Measuring similarity is suposed to be useful in determining how expert profiles fit for a given project description.\n",
    "\n",
    "The poposed alternatives to test similarity include:\n",
    "\n",
    "* LDA (topic modelling)\n",
    "* word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "For model training, we will be using a dataset based on documents associated to experts. Next we will compare other documents to measure similarity against trained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is located at 'data/sedici/Filtrar por_ Autor.html'\n",
    "\n",
    "First, we download the authors from the scholar websearch site (http://sedici.unlp.edu.ar/search-filter?field=author&rpp=100000). The `rpp=100000` sets the number of results per page in 100000. This will display the whole author list in a single web page (the number of authors is greater than 70000), which will be usefull for extracting authors ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmltree = html.parse('../data/sedici/filtrar_por_autor.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sections = htmltree.xpath('//*[@id=\"aspect_discovery_SearchFacetFilter_div_browse-by-author-results\"]//div/table//tr/td/a[contains(@href, \"authority\")]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a list of author names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the number of articles in parenthesis\n",
    "authors = []\n",
    "\n",
    "for n in a_sections:\n",
    "    name = n.text\n",
    "    name = re.sub(r'\\(\\d+\\)$', '', name)\n",
    "    name = [x.strip() for x in name.split(',')]\n",
    "    authors.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22380"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a list of *node ids* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ids = []\n",
    "\n",
    "for n in a_sections:\n",
    "    url = n.get('href')\n",
    "    url = re.search(r'(F\\d+)$', url).group(0)\n",
    "    node_ids.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22380"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(node_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Aamir', 'Muhammad N.'],\n",
       " ['Abad Santos', 'Natalia'],\n",
       " ['Abad', 'Jimena'],\n",
       " ['Abad', 'Juan Ernesto'],\n",
       " ['Abadi', 'Florencia'],\n",
       " ['Abadie', 'Diego Gustavo Edwin'],\n",
       " ['Abadíe', 'Mariana'],\n",
       " ['Abal', 'Adrián Alejandro'],\n",
       " ['Abal', 'Adrián Alejandro'],\n",
       " ['Abal', 'Mauricio']]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data set to a csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(authors, index=node_ids).to_csv('../data/sedici/authors.csv', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA\n",
    "\n",
    "Our first approach involves applying LDA to build expert profiles using topic models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, **expert profiles** are defined as a set topic models, and this models are trained using documents asociated to every expert. For instance, in academics this documents could be research papers where the expert is an author.\n",
    "\n",
    "**Project descriptions** are defined as the contributions to the topic models of the expert profiles.\n",
    "\n",
    "The similarity between the project descriptions and the expert profiles can be measured using the Jensen-Shannon Distance (see [ref](https://www.kaggle.com/ktattan/lda-and-document-similarity#Similarity-Queries-and-Unseen-Data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pj_fit",
   "language": "python",
   "name": "pj_fit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
