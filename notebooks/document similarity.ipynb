{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic similarity\n",
    "\n",
    "The aim of this notebook is to test a strategy to measure similarity between an **expert profile** and **project description**. \n",
    "\n",
    "Measuring similarity is suposed to be useful in determining how expert profiles fit for a given project description.\n",
    "\n",
    "The poposed alternatives to test similarity include:\n",
    "\n",
    "* LDA (topic modelling)\n",
    "* word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is organized as follows:\n",
    "\n",
    "* First, we load the data set\n",
    "* Second, we determine the languages of the author's articles to filter the majority language class.\n",
    "* Finally, we train a LDA model and implement a similarity function to evaluate a test case for finding authors with similar content to the content in the text case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "from time import process_time\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='../logs/console.log', \n",
    "                    level=logging.INFO,\n",
    "                    filemode='a', \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [x for x in listdir('../data/sedici') if 'node_articles_ciencias_informaticas' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for filename in filenames:\n",
    "    df = pd.concat([df, pd.read_csv('../data/sedici/{0}'.format(filename))], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65334, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55286</td>\n",
       "      <td>24446</td>\n",
       "      <td>Análisis automático del rendimiento de ejecuci...</td>\n",
       "      <td>La programación paralela más tradicional oblig...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55286</td>\n",
       "      <td>9582</td>\n",
       "      <td>Development and tuning framework of master/wor...</td>\n",
       "      <td>Parallel/distributed programming is a complex ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55286</td>\n",
       "      <td>20899</td>\n",
       "      <td>Método de Reducción de Incertidumbre basado en...</td>\n",
       "      <td>La problemática existente a raíz de la falta d...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55286</td>\n",
       "      <td>9524</td>\n",
       "      <td>Process tracking for dynamic tuning applicatio...</td>\n",
       "      <td>The computational resources need by the scient...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55286</td>\n",
       "      <td>23166</td>\n",
       "      <td>Mapas de riesgo de incendios forestales basado...</td>\n",
       "      <td>La valoración del riesgo en los incendios fore...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_id  article_id                                              title  \\\n",
       "0      55286       24446  Análisis automático del rendimiento de ejecuci...   \n",
       "1      55286        9582  Development and tuning framework of master/wor...   \n",
       "2      55286       20899  Método de Reducción de Incertidumbre basado en...   \n",
       "3      55286        9524  Process tracking for dynamic tuning applicatio...   \n",
       "4      55286       23166  Mapas de riesgo de incendios forestales basado...   \n",
       "\n",
       "                                            abstract language  \n",
       "0  La programación paralela más tradicional oblig...      NaN  \n",
       "1  Parallel/distributed programming is a complex ...      NaN  \n",
       "2  La problemática existente a raíz de la falta d...      NaN  \n",
       "3  The computational resources need by the scient...      NaN  \n",
       "4  La valoración del riesgo en los incendios fore...      NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be training models for a single language. Next step is to determine what are the proportion of languages usage in their content. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(LanguageDetector(), name=\"language_detector\", last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the language by analysing the abstract of each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('Language processing')\n",
    "\n",
    "def get_languages(tuples):\n",
    "    '''\n",
    "    Get languages for every row in tuples\n",
    "    \n",
    "    -----\n",
    "    param \n",
    "    tuples tuple with (index, row) from pandas.iterrows()\n",
    "    '''\n",
    "    \n",
    "    idx, row = tuples\n",
    "    \n",
    "    languages = []\n",
    "    \n",
    "    #if index in scale:\n",
    "    #    logger.info('Determining languages from article number {0}'.format(index))\n",
    "    #index = index + 1\n",
    "        \n",
    "    tic = process_time()\n",
    "    \n",
    "    doc = nlp(str(row['abstract']))\n",
    "    languages.append(doc._.language['language'])\n",
    "    \n",
    "    toc = process_time()\n",
    "    \n",
    "    logger.info(\"determininig language for article {0} took {1}ms.\".format(idx, toc-tic))\n",
    "    \n",
    "    return languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_lang = []\n",
    "\n",
    "with Pool(4) as p:\n",
    "    article_lang = p.map(get_languages, df.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65334"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language'] = [''.join(x) for x in article_lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/sedici/node_articles_ciencias_informaticas_with_language.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/sedici/node_articles_ciencias_informaticas_with_language.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "es    27812\n",
       "en     4325\n",
       "pt      168\n",
       "tl       99\n",
       "it        8\n",
       "ca        6\n",
       "af        4\n",
       "de        2\n",
       "so        1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc79b56db70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD+CAYAAADRRMnDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEt9JREFUeJzt3X+QXfV53/H3xwgcu8FBGEVDQY2wrUwrexyMxY82bsc1UxCQqXDGoRCP0TjEcmOR4jbtWEmaQG3T4I7tjGkcJjioFokTTEhc1FixrBIm2E3AEoaCBfWgYhikyiBb2Kb11A7k6R/3u/a1vivtanfZs3Tfr5k795znfM85z5V293PPj7ubqkKSpHEvGroBSdLCYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySps2ToBmbqpJNOqpUrVw7dhiS9oNx7771fq6plU417wYbDypUr2bVr19BtSNILSpLHpzPO00qSpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqvGA/BDcdKzd9es629dh1F83ZtiRpofPIQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUmTIckqxIcmeSh5LsTnJVq1+TZF+S+9vjwrF1fjnJniRfTnL+WH1tq+1JsmmsflqSe1r9k0mOm+sXKkmavukcOTwL/FJVrQbOATYmWd2W/WZVnd4e2wDaskuBVwNrgd9OckySY4CPAhcAq4HLxrbzgbatVwFPA1fM0euTJM3AlOFQVfur6ott+hngYeCUI6yyDrilqr5TVV8B9gBntceeqnq0qr4L3AKsSxLgTcBtbf0twMUzfUGSpNk7qmsOSVYCrwPuaaUrkzyQZHOSpa12CvDE2Gp7W+1w9ZcD36iqZw+pT7b/DUl2Jdl14MCBo2ldknQUph0OSX4Y+GPg3VX1LeAG4JXA6cB+4EPPS4djqurGqlpTVWuWLVv2fO9OkhatJdMZlORYRsHwiar6E4CqenJs+ceAP22z+4AVY6uf2mocpv514IQkS9rRw/h4SdIApnO3UoCbgIer6sNj9ZPHhr0Z+FKb3gpcmuTFSU4DVgFfAHYCq9qdSccxumi9taoKuBN4S1t/PXD77F6WJGk2pnPk8JPA24AHk9zfar/C6G6j04ECHgPeCVBVu5PcCjzE6E6njVX1HECSK4HtwDHA5qra3bb3HuCWJO8H7mMURpKkgUwZDlX1eSCTLNp2hHWuBa6dpL5tsvWq6lFGdzNJkhYAPyEtSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkzpThkGRFkjuTPJRkd5KrWv3EJDuSPNKel7Z6klyfZE+SB5KcMbat9W38I0nWj9Vfn+TBts71SfJ8vFhJ0vRM58jhWeCXqmo1cA6wMclqYBNwR1WtAu5o8wAXAKvaYwNwA4zCBLgaOBs4C7h6IlDamHeMrbd29i9NkjRTU4ZDVe2vqi+26WeAh4FTgHXAljZsC3Bxm14H3FwjdwMnJDkZOB/YUVUHq+ppYAewti17WVXdXVUF3Dy2LUnSAI7qmkOSlcDrgHuA5VW1vy36KrC8TZ8CPDG22t5WO1J97yT1yfa/IcmuJLsOHDhwNK1Lko7CtMMhyQ8Dfwy8u6q+Nb6sveOvOe6tU1U3VtWaqlqzbNmy53t3krRoTSsckhzLKBg+UVV/0spPtlNCtOenWn0fsGJs9VNb7Uj1UyepS5IGMp27lQLcBDxcVR8eW7QVmLjjaD1w+1j98nbX0jnAN9vpp+3AeUmWtgvR5wHb27JvJTmn7evysW1JkgawZBpjfhJ4G/Bgkvtb7VeA64Bbk1wBPA5c0pZtAy4E9gDfBt4OUFUHk7wP2NnGvbeqDrbpdwEfB14C/Fl7SJIGMmU4VNXngcN97uDcScYXsPEw29oMbJ6kvgt4zVS9SJLmh5+QliR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUmfKcEiyOclTSb40Vrsmyb4k97fHhWPLfjnJniRfTnL+WH1tq+1JsmmsflqSe1r9k0mOm8sXKEk6etM5cvg4sHaS+m9W1entsQ0gyWrgUuDVbZ3fTnJMkmOAjwIXAKuBy9pYgA+0bb0KeBq4YjYvSJI0e1OGQ1XdBRyc5vbWAbdU1Xeq6ivAHuCs9thTVY9W1XeBW4B1SQK8Cbitrb8FuPgoX4MkaY7N5prDlUkeaKedlrbaKcATY2P2ttrh6i8HvlFVzx5SlyQNaKbhcAPwSuB0YD/woTnr6AiSbEiyK8muAwcOzMcuJWlRmlE4VNWTVfVcVf0N8DFGp40A9gErxoae2mqHq38dOCHJkkPqh9vvjVW1pqrWLFu2bCatS5KmYUbhkOTksdk3AxN3Mm0FLk3y4iSnAauALwA7gVXtzqTjGF203lpVBdwJvKWtvx64fSY9SZLmzpKpBiT5Q+CNwElJ9gJXA29McjpQwGPAOwGqaneSW4GHgGeBjVX1XNvOlcB24Bhgc1Xtbrt4D3BLkvcD9wE3zdmrkyTNyJThUFWXTVI+7A/wqroWuHaS+jZg2yT1R/n+aSlJ0gLgJ6QlSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSZ0pwyHJ5iRPJfnSWO3EJDuSPNKel7Z6klyfZE+SB5KcMbbO+jb+kSTrx+qvT/JgW+f6JJnrFylJOjrTOXL4OLD2kNom4I6qWgXc0eYBLgBWtccG4AYYhQlwNXA2cBZw9USgtDHvGFvv0H1JkubZlOFQVXcBBw8prwO2tOktwMVj9Ztr5G7ghCQnA+cDO6rqYFU9DewA1rZlL6uqu6uqgJvHtiVJGshMrzksr6r9bfqrwPI2fQrwxNi4va12pPreSeqTSrIhya4kuw4cODDD1iVJU5n1Ben2jr/moJfp7OvGqlpTVWuWLVs2H7uUpEVppuHwZDslRHt+qtX3ASvGxp3aakeqnzpJXZI0oJmGw1Zg4o6j9cDtY/XL211L5wDfbKeftgPnJVnaLkSfB2xvy76V5Jx2l9LlY9uSJA1kyVQDkvwh8EbgpCR7Gd11dB1wa5IrgMeBS9rwbcCFwB7g28DbAarqYJL3ATvbuPdW1cRF7ncxuiPqJcCftYckaUBThkNVXXaYRedOMraAjYfZzmZg8yT1XcBrpupDkjR//IS0JKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOrMKhySPJXkwyf1JdrXaiUl2JHmkPS9t9SS5PsmeJA8kOWNsO+vb+EeSrJ/dS5IkzdZcHDn846o6varWtPlNwB1VtQq4o80DXACsao8NwA0wChPgauBs4Czg6olAkSQN4/k4rbQO2NKmtwAXj9VvrpG7gROSnAycD+yoqoNV9TSwA1j7PPQlSZqm2YZDAZ9Ncm+SDa22vKr2t+mvAsvb9CnAE2Pr7m21w9U7STYk2ZVk14EDB2bZuiTpcJbMcv03VNW+JD8K7EjyP8YXVlUlqVnuY3x7NwI3AqxZs2bOtitJ+kGzOnKoqn3t+SngU4yuGTzZThfRnp9qw/cBK8ZWP7XVDleXJA1kxuGQ5G8lOX5iGjgP+BKwFZi442g9cHub3gpc3u5aOgf4Zjv9tB04L8nSdiH6vFaTJA1kNqeVlgOfSjKxnT+oqs8k2QncmuQK4HHgkjZ+G3AhsAf4NvB2gKo6mOR9wM427r1VdXAWfUmSZmnG4VBVjwI/MUn968C5k9QL2HiYbW0GNs+0lxeSlZs+PWfbeuy6i+ZsW5I0zk9IS5I6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqWM4SJI6hoMkqbNgwiHJ2iRfTrInyaah+5GkxWxBhEOSY4CPAhcAq4HLkqwetitJWryWDN1Acxawp6oeBUhyC7AOeGjQrhaJlZs+PWfbeuy6i+ZsW5KGs1DC4RTgibH5vcDZhw5KsgHY0Gb/d5Ivz8G+TwK+NtWgfGAO9nR0puzLnoBp/v/NM3uavoXY1//vPf3YdAYtlHCYlqq6EbhxLreZZFdVrZnLbc6FhdiXPU2PPU3fQuzLnkYWxDUHYB+wYmz+1FaTJA1goYTDTmBVktOSHAdcCmwduCdJWrQWxGmlqno2yZXAduAYYHNV7Z6n3c/paao5tBD7sqfpsafpW4h92ROQqprvfUqSFriFclpJkrSAGA6SpI7hIEnqGA6SpI7hoCNKcsd0aotdkqumU1usJr5mkgE+Q/8ClOTYJP8iyW3t8YtJjp3XHhbj3Urtm/Y/Ac8Avwu8DthUVZ8dsKdlwDuAlYzdYlxVPzdQPz8EvBS4E3gjkLboZcBnqurvznM/DwKTfbEGqKp67Xz20zWRfLGqzjikdl9VvW7AnpYB72H0yyx/aKJeVW8aoJeHgJ8HbgJ+lu9/PU309MX57mlCkh8HbgCWV9VrkrwW+KdV9f4Be/pd4FhgSyu9DXiuqn5+vnpYEJ9zGMDPVdVHkpwPLGX0D/97wGDhANwOfA74r8BzA/Yx4Z3Au4G/Ddw7Vn8G+K0B+vkpRj9Q/gPwb8bqE7VBJLmM0Q+705KMf3DzeODgMF19zyeATwIXAf8cWA8cGKiXXwd+jdFvP/jwIcsKmPfAGvMxRl9TvwNQVQ8k+QNgsHAAzqyqnxib//Mk/30+G1is4TDxruUi4PeqaneSHGmFefDSqnrPwD18T1V9BPhIkl8EjgPewOib+HOMjrbmu5/HAZK8amJ6QpJ5PYo5xF8C+xn9YrQPjdWfAR4YpKPve3lV3ZTkqqr6C+AvkuwcopGqug24LcmvMXpz8eOMjmYWwqmLl1bVFw75EfDsUM00zyV5ZVX9T4Akr2Ce3zQu1nC4N8l24BXApiTHA38zcE9/muTCqto2cB+H+kfAN4Hr2/zPAjcDl8xnE0l+AXgX8Iok4z90jwf+23z2Mq4F1ePA3x+qhyP46/a8P8lFwP8CThywH4CvAncxOoK4HziHUcCeO2BPX0vySlpQJXkLo8Af0r8G7kzyaJtfCbx9PhtYrNccXgT8W2BpVf3LJH8H+LGq+tyAPT3D6Bz/dxl9U0+cS3/ZUD21vh6qqtVT1eahjx9hdArwN4DxvxT4TFUNdvomyeer6g3t/2/8m2nw/78kP8XoSG8F8B8ZXS+6pqr+y4A9PQicCdxdVae3o75/X1U/PWBPr2D06yn+AfA08BXgrYceoc5zTz/D6NcJrQQuZvTm41fn89rMYg2HGxgdKbypqv5ekqXAZ6vqzAF7ehHwVuC0qnpvC6yTq+qeoXpqff0+8FtVdXebPxvYWFWXD9mXppZkC3BVVX2jzZ8IfHComxxaDzur6swk9wNnV9V3kuyuqlcP0Mu/OqT0EkZ3cP4fgKo69NrIvEnyQFW9NskbgPcBHwR+vaq6v3PzfFmst7KeXVUbgf8LUFVPMzqvPqSPMjrEvqzND3Xh91CvB/4yyWNJHgP+CjgzyYOHnN7RwvPaiWAAaEdYg9091exNcgLwn4EdSW5ndFpuCMe3xxrgFxgdmZ7A6OL9GUdYbz5MXF+4CPhYVX2aef4ZtVivOfx1+7vVE+cYlzH8NYezq+qMJPfBKLDary8f2tqhG9CMvSjJ0vbmZ+LIYdDv+ap6c5u8JsmdwI8Anxmol38HkOQu4IyqeqbNXwPM3d/OnZl9SX4H+CfAB5K8mHl+M79Yw+F64FPAjya5FngLo2sQQ1qIgcWQ5101ax8C/irJH7X5nwGuHbCfH9DuoFoIljO61jfhu602pEsYvTH7YFV9I8nJ/OAt3M+7RXnNAb53++O5jC4c3lFVDw/cz1uBf8bocHYLLbCq6o+OuKJ0BElW8/3PEPx5VT00ZD8LUZJfZfTD+FOtdDHwyar6jeG6Gt6iDYeFaKEFlrRYJDkD+Idt9q6qum/IfhYCw0GS1FmsdytJko7AcJAkdQwHSVLHcJAkdf4f9oRsJ3DvMjEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['language'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with spanish documents, since 'es' is the majority language class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27812, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['language'] == 'es'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df['language'] == 'es']\n",
    "data = data[['author_id', 'article_id', 'title', 'abstract']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55286</td>\n",
       "      <td>24446</td>\n",
       "      <td>Análisis automático del rendimiento de ejecuci...</td>\n",
       "      <td>La programación paralela más tradicional oblig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55286</td>\n",
       "      <td>20899</td>\n",
       "      <td>Método de Reducción de Incertidumbre basado en...</td>\n",
       "      <td>La problemática existente a raíz de la falta d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55286</td>\n",
       "      <td>23166</td>\n",
       "      <td>Mapas de riesgo de incendios forestales basado...</td>\n",
       "      <td>La valoración del riesgo en los incendios fore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55286</td>\n",
       "      <td>23181</td>\n",
       "      <td>Algoritmos genéticos guiados para predicción d...</td>\n",
       "      <td>En este trabajo se propone una metodología par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55286</td>\n",
       "      <td>21622</td>\n",
       "      <td>Modelización y evaluación de performance en pa...</td>\n",
       "      <td>Se exponen las ideas principales de una línea ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_id  article_id                                              title  \\\n",
       "0      55286       24446  Análisis automático del rendimiento de ejecuci...   \n",
       "2      55286       20899  Método de Reducción de Incertidumbre basado en...   \n",
       "4      55286       23166  Mapas de riesgo de incendios forestales basado...   \n",
       "5      55286       23181  Algoritmos genéticos guiados para predicción d...   \n",
       "8      55286       21622  Modelización y evaluación de performance en pa...   \n",
       "\n",
       "                                            abstract  \n",
       "0  La programación paralela más tradicional oblig...  \n",
       "2  La problemática existente a raíz de la falta d...  \n",
       "4  La valoración del riesgo en los incendios fore...  \n",
       "5  En este trabajo se propone una metodología par...  \n",
       "8  Se exponen las ideas principales de una línea ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a single field 'content' by appending titles and abstracts, for each author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_results = []\n",
    "\n",
    "author_ids = data['author_id'].unique()\n",
    "\n",
    "for author_id in author_ids:\n",
    "    \n",
    "    content = ''\n",
    "    \n",
    "    for idx, row in data[data['author_id'] == author_id].iterrows():\n",
    "        content = content + '. '.join([str(row['title']), str(row['abstract'])]) + '\\n' \n",
    "        \n",
    "    concat_results.append((author_id, content))\n",
    "    \n",
    "df_content = pd.DataFrame(concat_results, columns=['author_id', 'content'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55286</td>\n",
       "      <td>Análisis automático del rendimiento de ejecuci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63510</td>\n",
       "      <td>Adaptabilidad en familia de aplicaciones web. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54180</td>\n",
       "      <td>Uso de VRPN en la implementación de una BCI p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58677</td>\n",
       "      <td>m-Experiencia de articulación universidad-escu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64654</td>\n",
       "      <td>Determinación del espesor de aleaciones metáli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_id                                            content\n",
       "0      55286  Análisis automático del rendimiento de ejecuci...\n",
       "1      63510  Adaptabilidad en familia de aplicaciones web. ...\n",
       "2      54180  Uso de VRPN en la implementación de una BCI p...\n",
       "3      58677  m-Experiencia de articulación universidad-escu...\n",
       "4      64654  Determinación del espesor de aleaciones metáli..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3225"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis automático del rendimiento de ejecución de programas paralelos. La programación paralela más tradicional obliga al programador, después de haber diseñado la aplicación, a analizar el rendimiento de la aplicación que se acaba de diseñar. El programador debe analizar una enorme cantidad de información obtenida de la ejecución de un programa. En este artículo, se propone una herramienta de análisis automático que permite a los programadores evitar esa tarea difícil. La herramienta se centra en la búsqueda de intervalos de ineficiencia a lo largo del tiempo de ejecución de la aplicación. Los problemas de rendimiento son analizados en detalle, en busca de posibles causas de la ineficiencia y sus soluciones.\n",
      "Método de Reducción de Incertidumbre basado en HPC. La problemática existente a raíz de la falta de exactitud que se encuentra en los parámetros de entrada en cualquier modelo científi co o físico, puede producir graves consecuencias en la salida del mismo si éste se trata de algún sistema crítico. Además, al citado problema deben sumarse las limitaciones impuestas por los propios modelos, las restricciones que agregan las soluciones numéricas y, por qué no, las provenientes de las propias implementaciones y versiones informáticas. Por tal motivo, resulta de gran interés el desarrollo de métodos informáticos que se enfoquen en el tratamiento de la incertidumbre de dichos valores de entrada para lograr así una predicción lo más confi able posible por parte del modelo en cuestión. En el presente trabajo se presenta un método basado en High Performance Computing en combinación con Cálculo Estadístico, el cual se ha evaluado y veri cado en casos reales aplicándolo a un modelo de comportamiento de incendios forestales.\n",
      "Mapas de riesgo de incendios forestales basados en experimentación factorial. La valoración del riesgo en los incendios forestales es un tema realmente signi cativo para la elaboración de políticas que permitan prevenir y mitigar los efectos de los incendios de una manera e ciente. Esta valoración usualmente se basa en la probabilidad de ignición debida a factores metereológicos o humanos, pero no suele considerar el riesgo de propagación cuando el fuego ya ha comenzado. Para evaluar el riesgo de propagación es necesario aplicar algún modelo de comportamiento para simular el frente de fuego. Sin embargo, este riesgo de propagación debe ser evaluado considerando múltiples escenarios. Por lo tanto, la cantidad de simulaciones que debe llevarse a cabo es enorme y resulta necesario aplicar técnicas de cómputo de altas prestaciones para que la metodología sea factible. En este artículo se describe un método para crear mapas de riesgo de propagación basados en experimentación factorial. La metodología fue aplicada en escala de la Europa meridional durante la temporada de verano de 2004.\n",
      "Algoritmos genéticos guiados para predicción de incendios forestales. En este trabajo se propone una metodología para mejorar las predicciones de incendios forestales. Utilizando un simulador ya desarrollado, se utiliza un algoritmo genético para realizar una búsqueda efectiva de parámetros de entrada tal que estos parámetros logren una buena predicción. A esto se le agrega el uso de conocimiento disponible para guiar las operaciones del algoritmo genético y reducir el gran espacio de búsqueda donde opera dicho algoritmo. Se proponen 2 métodos para guiar dicho algoritmo, el método computacional y el método analítico, este último además intenta verificar los resultados del método computacional. Dichos métodos se comparan mediante un estudio experimental mostrando los resultados la ganancia que supone a˜nadir guía a la búsqueda frente a no añadirla.\n",
      "Modelización y evaluación de performance en patrones de Procesamiento Paralelo. Se exponen las ideas principales de una línea de investigación conjunta en el área de Procesamiento Paralelo, que realizan la Universidad Autónoma de Barcelona (UAB) y la Universidad Nacional de La Plata. En este proyecto se estudia la especificación de patrones para la expresión de algoritmos paralelos en diferentes esquemas de procesamiento, la investigación sobre el modelo de prestaciones asociado con cada patrón y se realiza desarrollo experimental de algoritmos paralelos para tratamiento masivo de datos, comparando las prestaciones a partir de la codificación “directa” de los algoritmos con su expresión a través de los patrones modelizados.\n",
      "Entorno de desarrollo y sintonización de aplicaciones master/worker. La programación paralelo/distribuida es una tarea compleja que requiere un alto grado de experiencia para poder cubrir las expectativas de alto rendimiento comp utacional. El paradigma Master/Worker es uno de los paradigmas más comúnmente utilizados dado que es simple de entender y se adapta a un amplio rango de aplicaciones. Sin embargo, para obtener un rendimiento adecuado es menester sintonizar ciertos parámetros tales como la distribución de datos y el número de workers. En muchos casos, estos parámetros no pueden sintonizarse estáticamente dado que dependen de las condiciones particulares de cada ejecución. En este artículo, presentamos un entorno de sintonización dinámica que permite la adaptación de las aplicaciones a las condiciones dinámicas de ejecución, basado en un modelo teórico de comportamiento de aplicaciones Master/Worker. El entorno incluye un framework de desarrollo de aplicaciones Master/Worker, que permite al usuario concentrarse en el diseño de la aplicación, y una herramienta de monitorización/sintonización dinámica capaz de superar los cuellos de botella asociados a este tipo de aplicaciones.\n",
      "Process tracking for dynamic tuning applications on the grid. Los recursos computacionales requeridos por la comunidad científica para solucionar problemas son mayores que los ofrecidos por la infraestructura actual. La necesidad de mayores prestaciones se debe al constante progreso de la investigación, nuevos problemas o aumento del detalle en los problemas corrientes. Usuarios crean nuevos sistemas distribuidos en larga escala como sistemas Grid para lograr prestaciones deseadas. Sistemas Grid son generalmente construidos sobre los recursos computacionales disponibles como clusters, maquinas paralelas o dispositivos de almacenamiento distribuidos en diferentes organizaciones e interconectado por una red. Sintonizar aplicaciones en un sistema Grid no es fácil debido a las características de distribución de procesos en múltiples clusters controlados por diferentes sistemas de colas y heterogeneidad de la red de comunicaciones. Nosotros tenemos un entorno de monitorización, análisis y sintonización (MATE) que permite la sintonización dinámica de aplicaciones en entornos cluster. Debido a las muchas capas de software presente en sistemas Grid, dos ejecuciones de una misma aplicación pueden usar recursos distintos. Para sintonizar los procesos de la aplicación, nuestra herramienta debe localizar y seguir la ejecución de los procesos en el sistema. Nosotros llamamos eso como problema de localización de procesos. Este artículo presenta la integración de MATE con Gris y dos aproximaciones implementadas para solucionar el problema de localización de procesos dentro de sistemas Grid.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_content.iloc[0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a data set where each row contains the author id as well as their associated content of scientific productions (titles and abstracts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim.models import LdaModel\n",
    "from gensim import models, corpora, similarities\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import time\n",
    "from nltk import FreqDist\n",
    "from scipy.stats import entropy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first approach involves applying LDA to build expert profiles using topic models.\n",
    "\n",
    "Here, **expert profiles** are defined as a set topic models, and this models are trained using documents asociated to every expert. For instance, in academics this documents could be research papers where the expert is an author.\n",
    "\n",
    "**Project descriptions** are defined as the contributions to the topic models of the expert profiles.\n",
    "\n",
    "The similarity between the project descriptions and the expert profiles can be measured using the Jensen-Shannon Distance (see [ref](https://www.kaggle.com/ktattan/lda-and-document-similarity#Similarity-Queries-and-Unseen-Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA should work better with large datasets, however **content** have only titles and abstracts.\n",
    "\n",
    "Let's get an idea of what is the length of the content column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_size = []\n",
    "with Pool(4) as p:\n",
    "    content_size = p.map(len, df_content['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content['length'] = content_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc799359518>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_content['length'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author_id     int64\n",
       "content      object\n",
       "length        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      3225.000000\n",
       "mean       9357.815194\n",
       "std       18409.464828\n",
       "min         123.000000\n",
       "25%        2320.000000\n",
       "50%        4440.000000\n",
       "75%        9067.000000\n",
       "max      434430.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy is to train topic models based on the **whole content** of data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start LDA processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning processes from https://www.kaggle.com/ktattan/lda-and-document-similarity#Similarity-Queries-and-Unseen-Data\n",
    "\n",
    "def initial_clean(text):\n",
    "    \"\"\"\n",
    "    Function to clean text of websites, email addresess and any punctuation\n",
    "    We also lower case the text\n",
    "    \"\"\"\n",
    "    text = re.sub(\"((\\S+)?(http(s)?)(\\S+))|((\\S+)?(www)(\\S+))|((\\S+)?(\\@)(\\S+)?)\", \" \", text)\n",
    "    text = re.sub(\"[^a-zA-ZñÑáéíóúÁÉÍÓÚü ]\", \"\", text)\n",
    "    text = text.lower() # lower case the text\n",
    "    text = nltk.word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "stop_words = stopwords.words('spanish')\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"\n",
    "    Function that removes all stopwords from text\n",
    "    \"\"\"\n",
    "    return [word for word in text if word not in stop_words]\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    \"\"\"\n",
    "    Function to stem words, so plural and singular are treated the same\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = [stemmer.stem(word) for word in text]\n",
    "        text = [word for word in text if len(word) > 1] # make sure we have no 1 letter words\n",
    "    except IndexError: # the word \"oed\" broke this, so needed try except\n",
    "        pass\n",
    "    return text\n",
    "\n",
    "def apply_all(text):\n",
    "    \"\"\"\n",
    "    This function applies all the functions above into one\n",
    "    \"\"\"\n",
    "    return stem_words(remove_stop_words(initial_clean(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content['tokenized'] = df_content['content'].apply(apply_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63183"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first get a list of all words\n",
    "all_words = [word for item in list(df_content['tokenized']) for word in item]\n",
    "# use nltk fdist to get a frequency distribution of all words\n",
    "fdist = FreqDist(all_words)\n",
    "len(fdist) # number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['análisi',\n",
       " 'automático',\n",
       " 'rendimiento',\n",
       " 'ejecución',\n",
       " 'programa',\n",
       " 'paralelo',\n",
       " 'programación',\n",
       " 'paralela',\n",
       " 'tradicion',\n",
       " 'obliga']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cubana', 7),\n",
       " ('programático', 7),\n",
       " ('eliminado', 7),\n",
       " ('mastozoología', 7),\n",
       " ('period', 7),\n",
       " ('refracción', 7),\n",
       " ('eslabon', 7),\n",
       " ('competenciasla', 7),\n",
       " ('expandirs', 7),\n",
       " ('natación', 7)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose k and visually inspect the bottom 10 words of the top k\n",
    "k = 15000\n",
    "top_k_words = fdist.most_common(k)\n",
    "top_k_words[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function only to keep words in the top k words\n",
    "top_k_words,_ = zip(*fdist.most_common(k))\n",
    "top_k_words = set(top_k_words)\n",
    "def keep_top_k_words(text):\n",
    "    return [word for word in text if word in top_k_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content['tokenized'] = df_content['tokenized'].apply(keep_top_k_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lda(data):\n",
    "    \"\"\"\n",
    "    This function trains the lda model\n",
    "    We setup parameters like number of topics, the chunksize to use in Hoffman method\n",
    "    We also do 2 passes of the data since this is a small dataset, so we want the distributions to stabilize\n",
    "    \"\"\"\n",
    "    num_topics = 100\n",
    "    chunksize = 300\n",
    "    dictionary = corpora.Dictionary(data['tokenized'])\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in data['tokenized']]\n",
    "    t1 = time.time()\n",
    "    # low alpha means each document is only represented by a small number of topics, and vice versa\n",
    "    # low eta means each topic is only represented by a small number of words, and vice versa\n",
    "    lda = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary,\n",
    "                   alpha=1e-2, eta=0.5e-2, chunksize=chunksize, minimum_probability=0.0, passes=2)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to train LDA model on \", len(df), \"articles: \", (t2-t1)/60, \"min\")\n",
    "    return dictionary,corpus,lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LDA model on  32425 articles:  1.301446008682251 min\n"
     ]
    }
   ],
   "source": [
    "dictionary,corpus,lda = train_lda(df_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(64,\n",
       "  '0.051*\"investigación\" + 0.031*\"web\" + 0.028*\"proyecto\" + 0.028*\"universidad\" + 0.023*\"inteligencia\" + 0.021*\"nacion\" + 0.018*\"desarrollo\" + 0.018*\"línea\" + 0.018*\"ambient\" + 0.016*\"inteligent\" + 0.016*\"agent\" + 0.015*\"artifici\" + 0.015*\"trabajo\" + 0.015*\"objetivo\" + 0.012*\"patagonia\" + 0.012*\"computación\" + 0.011*\"planificación\" + 0.010*\"gener\" + 0.010*\"incentivar\" + 0.010*\"marco\"'),\n",
       " (36,\n",
       "  '0.023*\"tráfico\" + 0.020*\"cloud\" + 0.019*\"rede\" + 0.015*\"seguridad\" + 0.013*\"servicio\" + 0.012*\"comput\" + 0.011*\"internet\" + 0.011*\"red\" + 0.008*\"modelo\" + 0.008*\"nuevo\" + 0.008*\"infraestructura\" + 0.008*\"dato\" + 0.007*\"recurso\" + 0.007*\"análisi\" + 0.007*\"tecnología\" + 0.006*\"trabajo\" + 0.006*\"aplicacion\" + 0.006*\"distribución\" + 0.006*\"wireless\" + 0.006*\"gran\"'),\n",
       " (11,\n",
       "  '0.054*\"reconocimiento\" + 0.019*\"patron\" + 0.018*\"sistema\" + 0.017*\"video\" + 0.016*\"visión\" + 0.016*\"segmentación\" + 0.013*\"objeto\" + 0.013*\"método\" + 0.011*\"descriptor\" + 0.009*\"resultado\" + 0.009*\"cámara\" + 0.009*\"trabajo\" + 0.009*\"clasificación\" + 0.008*\"imágen\" + 0.008*\"escena\" + 0.008*\"tema\" + 0.008*\"partir\" + 0.007*\"mano\" + 0.007*\"entrenamiento\" + 0.007*\"real\"'),\n",
       " (94,\n",
       "  '0.013*\"informática\" + 0.011*\"trabajo\" + 0.010*\"metodología\" + 0.010*\"desarrollo\" + 0.010*\"resultado\" + 0.009*\"investigación\" + 0.009*\"entorno\" + 0.008*\"enseñanza\" + 0.008*\"softwar\" + 0.008*\"digit\" + 0.008*\"particular\" + 0.008*\"evaluación\" + 0.008*\"educativo\" + 0.007*\"tecnología\" + 0.007*\"aprendizaj\" + 0.006*\"proyecto\" + 0.006*\"presenta\" + 0.006*\"diferent\" + 0.006*\"objetivo\" + 0.006*\"línea\"'),\n",
       " (48,\n",
       "  '0.000*\"sistema\" + 0.000*\"trabajo\" + 0.000*\"desarrollo\" + 0.000*\"investigación\" + 0.000*\"herramienta\" + 0.000*\"información\" + 0.000*\"proceso\" + 0.000*\"problema\" + 0.000*\"modelo\" + 0.000*\"softwar\" + 0.000*\"objetivo\" + 0.000*\"basado\" + 0.000*\"proyecto\" + 0.000*\"dato\" + 0.000*\"presenta\" + 0.000*\"tecnología\" + 0.000*\"aplicación\" + 0.000*\"aplicacion\" + 0.000*\"web\" + 0.000*\"aprendizaj\"'),\n",
       " (23,\n",
       "  '0.016*\"sistema\" + 0.014*\"comprensión\" + 0.013*\"herramienta\" + 0.013*\"proceso\" + 0.011*\"programa\" + 0.009*\"información\" + 0.008*\"objetivo\" + 0.008*\"informática\" + 0.007*\"estrategia\" + 0.007*\"desarrollo\" + 0.007*\"proyecto\" + 0.007*\"análisi\" + 0.006*\"alumno\" + 0.006*\"trabajo\" + 0.005*\"softwar\" + 0.005*\"año\" + 0.005*\"artículo\" + 0.005*\"estudio\" + 0.005*\"conceptual\" + 0.004*\"uso\"'),\n",
       " (82,\n",
       "  '0.038*\"foro\" + 0.032*\"problema\" + 0.027*\"discusión\" + 0.020*\"técnico\" + 0.020*\"información\" + 0.018*\"pregunta\" + 0.016*\"web\" + 0.014*\"usuario\" + 0.014*\"solucion\" + 0.013*\"herramienta\" + 0.013*\"página\" + 0.011*\"búsqueda\" + 0.010*\"conocimiento\" + 0.009*\"ser\" + 0.009*\"hilo\" + 0.009*\"priorización\" + 0.009*\"particular\" + 0.009*\"respuesta\" + 0.009*\"dispon\" + 0.009*\"proyecto\"'),\n",
       " (47,\n",
       "  '0.041*\"arquitectura\" + 0.026*\"paralelo\" + 0.023*\"algoritmo\" + 0.019*\"aplicacion\" + 0.018*\"multicor\" + 0.017*\"cluster\" + 0.015*\"distribuido\" + 0.015*\"sistema\" + 0.014*\"paralela\" + 0.013*\"softwar\" + 0.013*\"cloud\" + 0.012*\"gpu\" + 0.011*\"procesador\" + 0.011*\"cómputo\" + 0.011*\"línea\" + 0.011*\"evaluación\" + 0.010*\"diferent\" + 0.010*\"tema\" + 0.010*\"tiempo\" + 0.010*\"desarrollo\"'),\n",
       " (60,\n",
       "  '0.044*\"dato\" + 0.024*\"sistema\" + 0.012*\"base\" + 0.010*\"trabajo\" + 0.010*\"aplicacion\" + 0.009*\"desarrollo\" + 0.009*\"distribuida\" + 0.008*\"información\" + 0.007*\"objetivo\" + 0.007*\"computación\" + 0.007*\"arquitectura\" + 0.006*\"tiempo\" + 0.006*\"forma\" + 0.006*\"distribuido\" + 0.006*\"problema\" + 0.006*\"grand\" + 0.006*\"necesidad\" + 0.006*\"modelo\" + 0.006*\"biométrico\" + 0.006*\"alto\"'),\n",
       " (9,\n",
       "  '0.000*\"sistema\" + 0.000*\"proceso\" + 0.000*\"desarrollo\" + 0.000*\"trabajo\" + 0.000*\"herramienta\" + 0.000*\"información\" + 0.000*\"visualización\" + 0.000*\"aprendizaj\" + 0.000*\"problema\" + 0.000*\"objetivo\" + 0.000*\"modelo\" + 0.000*\"softwar\" + 0.000*\"investigación\" + 0.000*\"proyecto\" + 0.000*\"aplicación\" + 0.000*\"web\" + 0.000*\"dato\" + 0.000*\"informática\" + 0.000*\"forma\" + 0.000*\"diferent\"')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show_topics method shows the the top num_words contributing to num_topics number of random topics\n",
    "lda.show_topics(num_topics=10, num_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine similarity with test document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../data/sedici/test.txt', 'r')\n",
    "\n",
    "test_data = file.readline() # just one line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clasificación automática de contenedores de demandas y habilidades en selección de expertos. La selección de expertos a menudo carece de descripciones útiles sobre las habilidades que los candidatos deben poseer para alcanzar las demandas requeridas para cubrir una posición dentro de una organización. Esta falta de descripciones inhibe la producción de evaluaciones precisas sobre la adecuación o congruencia entre demandas y habilidades (Adecuación Persona-Trabajo). Nosotros sostenemos que la clasificación automática de descripciones a partir de contextos de evaluación pueden contribuir a un mejor entendimiento de cómo los procesos de selección de expertos realmente trabajan. En este artículo, proponemos un enfoque de aprendizaje supervisado para la clasificación de descripciones que contengan demandas y habilidades a partir de transcripciones de tipo entrevista de trabajo. Asimismo, presentamos un caso de estudio de nominaciones de candidatos a ocupar posiciones ejecutivas en el servicio público. Nuestro modelo alcanzó un f1_score=0.71 (clase positiva), con posibles aplicaciones en procesos de selección de personas.\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bow = dictionary.doc2bow(apply_all(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc_distribution = np.array([tup[1] for tup in lda.get_document_topics(bow=new_bow)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get topic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_dist = np.array([[tup[1] for tup in lst] for lst in lda[corpus]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a similarity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jensen_shannon(query, matrix):\n",
    "    \"\"\"\n",
    "    This function implements a Jensen-Shannon similarity\n",
    "    between the input query (an LDA topic distribution for a document)\n",
    "    and the entire corpus of topic distributions.\n",
    "    It returns an array of length M where M is the number of documents in the corpus\n",
    "    \"\"\"\n",
    "    # lets keep with the p,q notation above\n",
    "    p = query[None,:].T # take transpose\n",
    "    q = matrix.T # transpose matrix\n",
    "    m = 0.5*(p + q)\n",
    "    return np.sqrt(0.5*(entropy(p,m) + entropy(q,m)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get most similar author's content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar_documents(query,matrix,k=10):\n",
    "    \"\"\"\n",
    "    This function implements the Jensen-Shannon distance above\n",
    "    and retruns the top k indices of the smallest jensen shannon distances\n",
    "    \"\"\"\n",
    "    sims = jensen_shannon(query,matrix) # list of jensen shannon distances\n",
    "    return sims.argsort()[:k] # the top k positional index of the smallest Jensen Shannon distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is surprisingly fast\n",
    "most_sim_ids = get_most_similar_documents(new_doc_distribution,doc_topic_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38      Reuso orientado a dominios: hacia un enfoque b...\n",
       "690     Identificación automática de usuarios conflict...\n",
       "745     Construcción colaborativa de ontologías CO-Pro...\n",
       "829     Técnicas y herramientas para desarrollo de sit...\n",
       "1070    Hacia la obtención de un modelo de base de dat...\n",
       "2599    Extendiendo la meta-arquitectura aportada por ...\n",
       "2924    Desarrollo de un esquema de Gestión de Riesgos...\n",
       "2972    Identificación automática de usuarios conflict...\n",
       "3102    Diseño y evaluación tempranos para priorizar l...\n",
       "3170    Diseño y evaluación tempranos para priorizar l...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_df = df_content[df_content.index.isin(most_sim_ids)]\n",
    "most_similar_df['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get authors from file and print authors with content similar to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = pd.read_csv('../data/sedici/authors.csv', names=['author_id', 'last_name', 'first_name', 'other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22380, 4)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for idx, item in authors['author_id'].iteritems():\n",
    "    result.append(item in most_similar_df['author_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>55260</td>\n",
       "      <td>Armentano</td>\n",
       "      <td>Marcelo G.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>56975</td>\n",
       "      <td>Baldo</td>\n",
       "      <td>Guillermo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>65150</td>\n",
       "      <td>Berdun</td>\n",
       "      <td>Franco</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855</th>\n",
       "      <td>54201</td>\n",
       "      <td>Caro</td>\n",
       "      <td>Angélica</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8207</th>\n",
       "      <td>53345</td>\n",
       "      <td>Gaetán</td>\n",
       "      <td>Gabriela</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12082</th>\n",
       "      <td>65486</td>\n",
       "      <td>Lugani</td>\n",
       "      <td>Carlos Fabián</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12919</th>\n",
       "      <td>66892</td>\n",
       "      <td>Martín</td>\n",
       "      <td>Adriana Elba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13049</th>\n",
       "      <td>66892</td>\n",
       "      <td>Martín</td>\n",
       "      <td>Adriana Elba</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13828</th>\n",
       "      <td>53349</td>\n",
       "      <td>Miranda</td>\n",
       "      <td>Gabriela</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18059</th>\n",
       "      <td>55275</td>\n",
       "      <td>Roqué Fourcade</td>\n",
       "      <td>Luis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18557</th>\n",
       "      <td>53326</td>\n",
       "      <td>Saldaño</td>\n",
       "      <td>Viviana E.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author_id       last_name     first_name other\n",
       "1129       55260       Armentano     Marcelo G.   NaN\n",
       "1499       56975           Baldo      Guillermo   NaN\n",
       "2141       65150          Berdun         Franco   NaN\n",
       "3855       54201            Caro       Angélica   NaN\n",
       "8207       53345          Gaetán       Gabriela   NaN\n",
       "12082      65486          Lugani  Carlos Fabián   NaN\n",
       "12919      66892          Martín   Adriana Elba   NaN\n",
       "13049      66892          Martín   Adriana Elba   NaN\n",
       "13828      53349         Miranda       Gabriela   NaN\n",
       "18059      55275  Roqué Fourcade           Luis   NaN\n",
       "18557      53326         Saldaño     Viviana E.   NaN"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors.iloc[result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the articles of the authors retrieved by the similarity funcion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>55260</td>\n",
       "      <td>70804</td>\n",
       "      <td>Identificación automática de usuarios conflict...</td>\n",
       "      <td>Actualmente, las redes sociales cumplen un pap...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6938</th>\n",
       "      <td>55260</td>\n",
       "      <td>56972</td>\n",
       "      <td>Inferencia de roles de equipo a partir de cond...</td>\n",
       "      <td>En un entorno de trabajo colaborativo, grupos ...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6939</th>\n",
       "      <td>55260</td>\n",
       "      <td>52117</td>\n",
       "      <td>Clasificación de conductas colaborativas a par...</td>\n",
       "      <td>En un entorno de trabajo colaborativo, grupos ...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6940</th>\n",
       "      <td>55260</td>\n",
       "      <td>21462</td>\n",
       "      <td>El proyecto AGUSINA</td>\n",
       "      <td>Las vías rápidas de información se nos present...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6941</th>\n",
       "      <td>55260</td>\n",
       "      <td>41726</td>\n",
       "      <td>Inducción de preferencias a partir del context...</td>\n",
       "      <td>Los sistemas de recomendación que usan técnica...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6942</th>\n",
       "      <td>55260</td>\n",
       "      <td>65939</td>\n",
       "      <td>Detección de conductas a partir de interaccion...</td>\n",
       "      <td>La observación y el análisis de la dinámica de...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author_id  article_id  \\\n",
       "6937      55260       70804   \n",
       "6938      55260       56972   \n",
       "6939      55260       52117   \n",
       "6940      55260       21462   \n",
       "6941      55260       41726   \n",
       "6942      55260       65939   \n",
       "\n",
       "                                                  title  \\\n",
       "6937  Identificación automática de usuarios conflict...   \n",
       "6938  Inferencia de roles de equipo a partir de cond...   \n",
       "6939  Clasificación de conductas colaborativas a par...   \n",
       "6940                                El proyecto AGUSINA   \n",
       "6941  Inducción de preferencias a partir del context...   \n",
       "6942  Detección de conductas a partir de interaccion...   \n",
       "\n",
       "                                               abstract language  \n",
       "6937  Actualmente, las redes sociales cumplen un pap...       es  \n",
       "6938  En un entorno de trabajo colaborativo, grupos ...       es  \n",
       "6939  En un entorno de trabajo colaborativo, grupos ...       es  \n",
       "6940  Las vías rápidas de información se nos present...       es  \n",
       "6941  Los sistemas de recomendación que usan técnica...       es  \n",
       "6942  La observación y el análisis de la dinámica de...       es  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['author_id'] == 55260]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we test a strategy to measure similarity between documents and expert profiles. \n",
    "This approach introduce an alternative for expert finding, where queries are represented by text documents, and expert profiles are represented by LDA models.\n",
    "Results of the similarity function must be validated somehow. This validation could be made by introducing\n",
    "feedback from experts from personel selection domain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pj_fit",
   "language": "python",
   "name": "pj_fit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
