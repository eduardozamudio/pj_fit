{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic similarity\n",
    "\n",
    "The aim of this notebook is to test a strategy to measure similarity between an **expert profile** and **project description**. \n",
    "\n",
    "Measuring similarity is suposed to be useful in determining how expert profiles fit for a given project description.\n",
    "\n",
    "The poposed alternatives to test similarity include:\n",
    "\n",
    "* LDA (topic modelling)\n",
    "* word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "For model training, we will be using a dataset based on documents associated to experts. Next we will compare other documents to measure similarity against trained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is located at 'data/sedici/filtrar_por_autor.html'\n",
    "\n",
    "First, we download the authors from the scholar websearch site (http://sedici.unlp.edu.ar/search-filter?field=author&rpp=100000). The `rpp=100000` sets the number of results per page in 100000. This will display the whole author list in a single web page (the number of authors is greater than 70000), which will be usefull for extracting authors ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='../logs/console.log', \n",
    "                    level=logging.INFO,\n",
    "                    filemode='w', \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmltree = html.parse('../data/sedici/filtrar_por_autor.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sections = htmltree.xpath('//*[@id=\"aspect_discovery_SearchFacetFilter_div_browse-by-author-results\"]//div/table//tr/td/a[contains(@href, \"authority\")]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a list of author names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the number of articles in parenthesis\n",
    "authors = []\n",
    "\n",
    "for n in a_sections:\n",
    "    name = n.text\n",
    "    name = re.sub(r'\\(\\d+\\)$', '', name)\n",
    "    name = [x.strip() for x in name.split(',')]\n",
    "    authors.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a list of *node ids* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sections.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sections[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trailing_numbers(urls):\n",
    "    '''\n",
    "    Retruns the trailing numbers for every string in urls\n",
    "    \n",
    "    ------\n",
    "    param\n",
    "    url list of strings (urls)\n",
    "    ------\n",
    "    return\n",
    "    list of numbers\n",
    "    '''\n",
    "    node_ids = []\n",
    "\n",
    "    for n in urls:\n",
    "        url = n.get('href')\n",
    "        url = re.search(r'(\\d+)$', url).group(0)\n",
    "        node_ids.append(url)\n",
    "                               \n",
    "    return node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ids = get_trailing_numbers(a_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(node_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data set to a csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(authors, index=node_ids).to_csv('../data/sedici/authors.csv', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the author's documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data of the authors, we must get the documents associated to each author. \n",
    "\n",
    "First, we define a function to get article ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_ids(author_id):\n",
    "    '''\n",
    "    Gets the articles ids for a given author id\n",
    "    \n",
    "    -------\n",
    "    param\n",
    "    author_id id of the author \n",
    "    \n",
    "    -------\n",
    "    returns\n",
    "    list\n",
    "    '''\n",
    "\n",
    "    rpp = 1000\n",
    "    article_ids = []\n",
    "\n",
    "    url = 'http://sedici.unlp.edu.ar/discover?filtertype_0=author&filter_relational_operator_0=authority&filter_0=http://voc.sedici.unlp.edu.ar/node/{0}&rpp={1}'.format(author_id, rpp)\n",
    "\n",
    "    htmltree = html.parse(url)\n",
    "\n",
    "    a_sections = htmltree.xpath('//*[@id=\"aspect_discovery_SimpleSearch_div_search-results\"]/ul/ul//li/div[2]/div[1]/span/a')\n",
    "\n",
    "    article_ids = get_trailing_numbers(a_sections)\n",
    "    \n",
    "    return set(article_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id = 53309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_ids = get_article_ids(node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(article_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "article_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we define a function to get article title and resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_article_texts(article_id):\n",
    "    '''\n",
    "    Gets the title and resume for a given article id\n",
    "    \n",
    "    ------\n",
    "    param\n",
    "    article_id id of the article\n",
    "    \n",
    "    ------\n",
    "    return \n",
    "    title, resume\n",
    "    '''\n",
    "    title, resume = '', ''\n",
    "\n",
    "    try:\n",
    "        url = 'http://sedici.unlp.edu.ar/handle/10915/{}'.format(article_id)\n",
    "\n",
    "        htmltree = html.parse(url)\n",
    "\n",
    "        #article_section = htmltree.xpath('//*[@id=\"aspect_artifactbrowser_ItemViewer_div_item-view\"]/div[1]/h1/text()')        \n",
    "        article_section = htmltree.xpath('..//h1/text()')        \n",
    "        title = article_section[0]\n",
    "\n",
    "        #article_section = htmltree.xpath('//*[@id=\"aspect_artifactbrowser_ItemViewer_div_item-view\"]/div[1]/div[4]/div/p/text()')\n",
    "        #if len(article_section) == 0:            \n",
    "        #    article_section = htmltree.xpath('//*[@id=\"aspect_artifactbrowser_ItemViewer_div_item-view\"]/div[1]/div[1]/span[2]/text()')\n",
    "        #    title = title + '. ' + article_section[0]\n",
    "            \n",
    "        #    article_section = htmltree.xpath('//*[@id=\"aspect_artifactbrowser_ItemViewer_div_item-view\"]/div[1]/div[5]/div/p/text()')\n",
    "        article_section = htmltree.xpath('//div[@class=\"simple-item-view-description\"]//div//p/text()')\n",
    "        resume = article_section[0]\n",
    "        \n",
    "    except Exception as inst:\n",
    "        logger = logging.getLogger('Articles logger')    \n",
    "        logger.error('Article parser error: article id {0}, type error {1}'.format(article_id, type(inst)))\n",
    "    \n",
    "    return article_id, title, resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_id = '70802'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_article_texts(article_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get all together to get titles and resumes for every article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id = '53309'\n",
    "\n",
    "\n",
    "articles = []\n",
    "\n",
    "article_ids = get_article_ids(node_id)\n",
    "\n",
    "for a in article_ids:\n",
    "    articles.append((node_id,) + get_article_texts(a))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_articles(node_ids, start_idx, end_idx):\n",
    "    '''\n",
    "    Gets the articles from node_ids \n",
    "    \n",
    "    -----\n",
    "    param\n",
    "    node_ids list of node ids\n",
    "    \n",
    "    -----\n",
    "    param\n",
    "    start_idx starting index of the node_ids\n",
    "    \n",
    "    -----\n",
    "    param\n",
    "    end_idx ending index of the node_ids\n",
    "    '''\n",
    "    articles = []\n",
    "    \n",
    "    assert((start_idx <= end_idx))\n",
    "    assert(start_idx >= 0)\n",
    "    assert((end_idx <= len(node_ids)))\n",
    "    \n",
    "    logger = logging.getLogger('Articles logger')\n",
    "    logger.setLevel('INFO')\n",
    "    \n",
    "    logger.info(\"Start getting articles from node id {0} to {1}\".format(start_idx, end_idx))\n",
    "\n",
    "    for i in range(start_idx, end_idx):\n",
    "        node_id = node_ids[i]\n",
    "        \n",
    "        logger.info(\"Getting articles for node id {0}\".format(node_id))\n",
    "\n",
    "        article_ids = get_article_ids(node_id)\n",
    "\n",
    "        for a in article_ids:\n",
    "            articles.append((node_id,) + get_article_texts(a))\n",
    "    \n",
    "    logger.info(\"Finish getting articles from node id {0} to {1}\".format(start_idx, end_idx))\n",
    "    \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to download articles in a batch process, so we can store results in different files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 100\n",
    "start, end = 0, 1000\n",
    "\n",
    "for i in range(start, end, batch):\n",
    "    from_idx = i\n",
    "    to_idx = i + batch\n",
    "    \n",
    "    logger = logging.getLogger('Article logger')\n",
    "    logger.info('Starting batch from index {0} to {1}'.format(from_idx, to_idx))\n",
    "    \n",
    "    articles = get_articles(node_ids, from_idx, to_idx)\n",
    "    articles = pd.DataFrame(articles, columns=['author_id', 'article_id', 'title', 'abstract'])\n",
    "\n",
    "    articles.to_csv('../data/sedici/node_articles_{}-{}.csv'.format(from_idx, to_idx), index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LDA\n",
    "\n",
    "Our first approach involves applying LDA to build expert profiles using topic models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, **expert profiles** are defined as a set topic models, and this models are trained using documents asociated to every expert. For instance, in academics this documents could be research papers where the expert is an author.\n",
    "\n",
    "**Project descriptions** are defined as the contributions to the topic models of the expert profiles.\n",
    "\n",
    "The similarity between the project descriptions and the expert profiles can be measured using the Jensen-Shannon Distance (see [ref](https://www.kaggle.com/ktattan/lda-and-document-similarity#Similarity-Queries-and-Unseen-Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pj_fit",
   "language": "python",
   "name": "pj_fit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
